{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a49f921-5c80-4f43-b53f-f1028bfcd36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc581fa-7387-46fe-97e9-4f81766bdb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58b25dfe-20ec-40a1-809c-f8f4f445bf45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Replace these numbers with your actual counts\n",
    "number_of_cancerous_images = 203  # Example count\n",
    "number_of_healthy_images = 133     # Example count\n",
    "\n",
    "# Labels for your categories\n",
    "categories = ['Cancerous', 'Healthy']\n",
    "\n",
    "# Values corresponding to each category\n",
    "values = [number_of_cancerous_images, number_of_healthy_images]\n",
    "\n",
    "# Creating the bar plot\n",
    "plt.bar(categories, values)\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Number of Images by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Number of Images')\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd6ead4-c7f6-4d4a-b933-6726067803c2",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ac882b-0b6b-447c-bb0f-aaae3f13d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained ResNet model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all the parameters in the model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final fully connected layer\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 1)  # For binary classification\n",
    "\n",
    "# Check if a GPU is available and move the model to GPU if it is\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d3b6822-ac78-4fa3-bccb-003ee5b6aa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image to 224x224 for ResNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalization for ResNet\n",
    "])\n",
    "\n",
    "# Load your dataset\n",
    "dataset = datasets.ImageFolder(\"C:/Users/lenovo/Downloads/Biglycan breast cancer dataset/\", transform=transform)\n",
    "\n",
    "# Splitting dataset into train and validation\n",
    "train_size = int(0.75 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9137f61b-33dd-475f-8e1d-51d72df0526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47a9184a-8780-4fca-a9aa-7d4e5becb859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7290124371647835\n",
      "Epoch 2, Loss: 0.6313061565160751\n",
      "Epoch 3, Loss: 0.555512048304081\n",
      "Epoch 4, Loss: 0.5177107155323029\n",
      "Epoch 5, Loss: 0.4701675958931446\n",
      "Epoch 6, Loss: 0.44719403237104416\n",
      "Epoch 7, Loss: 0.40705810487270355\n",
      "Epoch 8, Loss: 0.3913630433380604\n",
      "Epoch 9, Loss: 0.3757568448781967\n",
      "Epoch 10, Loss: 0.3611692078411579\n",
      "Epoch 11, Loss: 0.3345712088048458\n",
      "Epoch 12, Loss: 0.31701556220650673\n",
      "Epoch 13, Loss: 0.3297787085175514\n",
      "Epoch 14, Loss: 0.30899257212877274\n",
      "Epoch 15, Loss: 0.2997094988822937\n",
      "Epoch 16, Loss: 0.2935173325240612\n",
      "Epoch 17, Loss: 0.2946882750838995\n",
      "Epoch 18, Loss: 0.27072738483548164\n",
      "Epoch 19, Loss: 0.28670958802103996\n",
      "Epoch 20, Loss: 0.27810963802039623\n",
      "Epoch 21, Loss: 0.2902575936168432\n",
      "Epoch 22, Loss: 0.2591111622750759\n",
      "Epoch 23, Loss: 0.24639404565095901\n",
      "Epoch 24, Loss: 0.24084755592048168\n",
      "Epoch 25, Loss: 0.23276295140385628\n",
      "Epoch 26, Loss: 0.2341508287936449\n",
      "Epoch 27, Loss: 0.22378451377153397\n",
      "Epoch 28, Loss: 0.22220702841877937\n",
      "Epoch 29, Loss: 0.2687173802405596\n",
      "Epoch 30, Loss: 0.24641061574220657\n",
      "Epoch 31, Loss: 0.2437836416065693\n",
      "Epoch 32, Loss: 0.22430886887013912\n",
      "Epoch 33, Loss: 0.19285226613283157\n",
      "Epoch 34, Loss: 0.23279109969735146\n",
      "Epoch 35, Loss: 0.18177317827939987\n",
      "Epoch 36, Loss: 0.20800695568323135\n",
      "Epoch 37, Loss: 0.1884018387645483\n",
      "Epoch 38, Loss: 0.1855334285646677\n",
      "Epoch 39, Loss: 0.19399943947792053\n",
      "Epoch 40, Loss: 0.2002429310232401\n",
      "Epoch 41, Loss: 0.19195437896996737\n",
      "Epoch 42, Loss: 0.17757901921868324\n",
      "Epoch 43, Loss: 0.23777499608695507\n",
      "Epoch 44, Loss: 0.20202052406966686\n",
      "Epoch 45, Loss: 0.16392291523516178\n",
      "Epoch 46, Loss: 0.16768535505980253\n",
      "Epoch 47, Loss: 0.17130735330283642\n",
      "Epoch 48, Loss: 0.20729904621839523\n",
      "Epoch 49, Loss: 0.16572741512209177\n",
      "Epoch 50, Loss: 0.16371606476604939\n",
      "Epoch 51, Loss: 0.1684731151908636\n",
      "Epoch 52, Loss: 0.1624303562566638\n",
      "Epoch 53, Loss: 0.17559609562158585\n",
      "Epoch 54, Loss: 0.16370556876063347\n",
      "Epoch 55, Loss: 0.16157402656972408\n",
      "Epoch 56, Loss: 0.17980220913887024\n",
      "Epoch 57, Loss: 0.15446717012673616\n",
      "Epoch 58, Loss: 0.15717407129704952\n",
      "Epoch 59, Loss: 0.15671374835073948\n",
      "Epoch 60, Loss: 0.1689127441495657\n",
      "Epoch 61, Loss: 0.16236832737922668\n",
      "Epoch 62, Loss: 0.1351309549063444\n",
      "Epoch 63, Loss: 0.1353853945620358\n",
      "Epoch 64, Loss: 0.1511395564302802\n",
      "Epoch 65, Loss: 0.14261736813932657\n",
      "Epoch 66, Loss: 0.13838676176965237\n",
      "Epoch 67, Loss: 0.12711234856396914\n",
      "Epoch 68, Loss: 0.1359032178297639\n",
      "Epoch 69, Loss: 0.13473108783364296\n",
      "Epoch 70, Loss: 0.13113150466233492\n",
      "Epoch 71, Loss: 0.16186334006488323\n",
      "Epoch 72, Loss: 0.15031337924301624\n",
      "Epoch 73, Loss: 0.1874390309676528\n",
      "Epoch 74, Loss: 0.15910184383392334\n",
      "Epoch 75, Loss: 0.12190717086195946\n",
      "Epoch 76, Loss: 0.1346330540254712\n",
      "Epoch 77, Loss: 0.17276375833898783\n",
      "Epoch 78, Loss: 0.17428349517285824\n",
      "Epoch 79, Loss: 0.11422049347311258\n",
      "Epoch 80, Loss: 0.1317106345668435\n",
      "Epoch 81, Loss: 0.12196131702512503\n",
      "Epoch 82, Loss: 0.11606151796877384\n",
      "Epoch 83, Loss: 0.11834350414574146\n",
      "Epoch 84, Loss: 0.11619237996637821\n",
      "Epoch 85, Loss: 0.16412154585123062\n",
      "Epoch 86, Loss: 0.12084425427019596\n",
      "Epoch 87, Loss: 0.10611622501164675\n",
      "Epoch 88, Loss: 0.11640237830579281\n",
      "Epoch 89, Loss: 0.1410419074818492\n",
      "Epoch 90, Loss: 0.11915773060172796\n",
      "Epoch 91, Loss: 0.12719598785042763\n",
      "Epoch 92, Loss: 0.13552165124565363\n",
      "Epoch 93, Loss: 0.10433012805879116\n",
      "Epoch 94, Loss: 0.11654168646782637\n",
      "Epoch 95, Loss: 0.08974363701418042\n",
      "Epoch 96, Loss: 0.1136840172111988\n",
      "Epoch 97, Loss: 0.10234508570283651\n",
      "Epoch 98, Loss: 0.1216138550080359\n",
      "Epoch 99, Loss: 0.12618066649883986\n",
      "Epoch 100, Loss: 0.10067424736917019\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100  # Define the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        \n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels.unsqueeze(1).type_as(outputs))  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
    "    \n",
    "    # Validation loop can be added here to monitor validation loss and accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aff351e4-0f2e-4bb8-9878-0905f34a6c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[44  4]\n",
      " [ 3 33]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.94      0.92      0.93        48\n",
      "   Cancerous       0.89      0.92      0.90        36\n",
      "\n",
      "    accuracy                           0.92        84\n",
      "   macro avg       0.91      0.92      0.92        84\n",
      "weighted avg       0.92      0.92      0.92        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_targets, np.array(all_preds).flatten()))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_targets, np.array(all_preds).flatten(), target_names=['Healthy', 'Cancerous']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b131c0a4-099e-4689-b5e7-7ce78bda5f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.67%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Apply sigmoid since we used BCEWithLogitsLoss\n",
    "        predicted_probs = torch.sigmoid(outputs)\n",
    "        \n",
    "        # Convert probabilities to predicted class (0 or 1)\n",
    "        predicted = predicted_probs > 0.5\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.flatten() == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42dd7b3-e2e8-431e-88af-b9ba5f51f673",
   "metadata": {},
   "source": [
    "## RESNET-- 10 FOLD CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cff21e6f-5d07-4308-bca8-a9a5935b9c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3196\n",
      "Epoch [20/50], Training Loss: 0.2666\n",
      "Epoch [30/50], Training Loss: 0.2222\n",
      "Epoch [40/50], Training Loss: 0.1879\n",
      "Epoch [50/50], Training Loss: 0.2332\n",
      "Validation Loss: 0.5526, Accuracy: 79.41%, Precision: 0.6842, Recall: 0.9286, F1-score: 0.7879\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3348\n",
      "Epoch [20/50], Training Loss: 0.2764\n",
      "Epoch [30/50], Training Loss: 0.2596\n",
      "Epoch [40/50], Training Loss: 0.2357\n",
      "Epoch [50/50], Training Loss: 0.1832\n",
      "Validation Loss: 0.1796, Accuracy: 94.12%, Precision: 0.9231, Recall: 0.9231, F1-score: 0.9231\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3615\n",
      "Epoch [20/50], Training Loss: 0.2675\n",
      "Epoch [30/50], Training Loss: 0.2457\n",
      "Epoch [40/50], Training Loss: 0.2045\n",
      "Epoch [50/50], Training Loss: 0.2098\n",
      "Validation Loss: 0.3130, Accuracy: 82.35%, Precision: 0.6471, Recall: 1.0000, F1-score: 0.7857\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3654\n",
      "Epoch [20/50], Training Loss: 0.2767\n",
      "Epoch [30/50], Training Loss: 0.2293\n",
      "Epoch [40/50], Training Loss: 0.2015\n",
      "Epoch [50/50], Training Loss: 0.1642\n",
      "Validation Loss: 0.2273, Accuracy: 94.12%, Precision: 0.9333, Recall: 0.9333, F1-score: 0.9333\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3736\n",
      "Epoch [20/50], Training Loss: 0.2593\n",
      "Epoch [30/50], Training Loss: 0.2244\n",
      "Epoch [40/50], Training Loss: 0.1838\n",
      "Epoch [50/50], Training Loss: 0.1524\n",
      "Validation Loss: 0.3526, Accuracy: 85.29%, Precision: 1.0000, Recall: 0.6667, F1-score: 0.8000\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3125\n",
      "Epoch [20/50], Training Loss: 0.2729\n",
      "Epoch [30/50], Training Loss: 0.2268\n",
      "Epoch [40/50], Training Loss: 0.2141\n",
      "Epoch [50/50], Training Loss: 0.1949\n",
      "Validation Loss: 0.2240, Accuracy: 82.35%, Precision: 0.6875, Recall: 0.9167, F1-score: 0.7857\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3261\n",
      "Epoch [20/50], Training Loss: 0.2565\n",
      "Epoch [30/50], Training Loss: 0.2101\n",
      "Epoch [40/50], Training Loss: 0.1773\n",
      "Epoch [50/50], Training Loss: 0.1820\n",
      "Validation Loss: 0.2852, Accuracy: 81.82%, Precision: 0.9000, Recall: 0.6429, F1-score: 0.7500\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3338\n",
      "Epoch [20/50], Training Loss: 0.2879\n",
      "Epoch [30/50], Training Loss: 0.2523\n",
      "Epoch [40/50], Training Loss: 0.2197\n",
      "Epoch [50/50], Training Loss: 0.1934\n",
      "Validation Loss: 0.1679, Accuracy: 93.94%, Precision: 1.0000, Recall: 0.8947, F1-score: 0.9444\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3172\n",
      "Epoch [20/50], Training Loss: 0.2773\n",
      "Epoch [30/50], Training Loss: 0.2579\n",
      "Epoch [40/50], Training Loss: 0.1971\n",
      "Epoch [50/50], Training Loss: 0.1840\n",
      "Validation Loss: 0.1611, Accuracy: 93.94%, Precision: 0.8333, Recall: 1.0000, F1-score: 0.9091\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3325\n",
      "Epoch [20/50], Training Loss: 0.2837\n",
      "Epoch [30/50], Training Loss: 0.2166\n",
      "Epoch [40/50], Training Loss: 0.1873\n",
      "Epoch [50/50], Training Loss: 0.1364\n",
      "Validation Loss: 0.1748, Accuracy: 93.94%, Precision: 1.0000, Recall: 0.8000, F1-score: 0.8889\n",
      "\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "Average Loss: 0.2638\n",
      "Average Accuracy: 88.13%\n",
      "Average Precision: 0.8609\n",
      "Average Recall: 0.8706\n",
      "Average F1-score: 0.8508\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Define device upfront\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = 'C:/Users/lenovo/Downloads/Biglycan breast cancer dataset/'\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "def get_model(device):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 1)  # Adjusted for binary classification\n",
    "    return model.to(device)\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, device, epochs=50):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)  # Adjust for BCEWithLogitsLoss\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))  # Adjust labels' shape\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        if (epoch+1) % 10 == 0:  # Print every 10 epochs\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Training Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "\n",
    "def evaluate_model(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            running_loss += loss.item()\n",
    "            preds = torch.sigmoid(outputs) > 0.5  # Convert to binary predictions\n",
    "            # Ensure preds and labels are at least 1D arrays before extending\n",
    "            all_predictions.extend(np.atleast_1d(preds.squeeze().cpu().numpy()))\n",
    "            all_labels.extend(np.atleast_1d(labels.cpu().numpy()))\n",
    "\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(all_labels, all_predictions, average='binary')\n",
    "\n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "    accuracy = (all_predictions == all_labels).mean() * 100\n",
    "    print(f'Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1_score:.4f}')\n",
    "    return avg_loss, accuracy, precision, recall, f1_score\n",
    "\n",
    "\n",
    "# Criterion adjusted for binary classification with a single output unit\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "k_folds = 10\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    train_subsampler = Subset(dataset, train_ids)\n",
    "    val_subsampler = Subset(dataset, val_ids)\n",
    "    \n",
    "    train_loader = DataLoader(train_subsampler, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_subsampler, batch_size=16)\n",
    "    \n",
    "    model = get_model(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Now specifying epochs=100 for training\n",
    "    train_model(model, train_loader, criterion, optimizer, device, epochs=50)\n",
    "    \n",
    "    avg_loss, accuracy, precision, recall, f1_score = evaluate_model(model, val_loader, criterion, device)\n",
    "\n",
    "    results.append((avg_loss, accuracy, precision, recall, f1_score))\n",
    "\n",
    "\n",
    "# After all folds are complete, calculate and print the average loss and accuracy across all folds\n",
    "# After evaluating all folds\n",
    "avg_loss = np.mean([result[0] for result in results])\n",
    "avg_accuracy = np.mean([result[1] for result in results])\n",
    "avg_precision = np.mean([result[2] for result in results])\n",
    "avg_recall = np.mean([result[3] for result in results])\n",
    "avg_f1_score = np.mean([result[4] for result in results])\n",
    "\n",
    "print(f'\\nK-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "print(f'Average Loss: {avg_loss:.4f}')\n",
    "print(f'Average Accuracy: {avg_accuracy:.2f}%')\n",
    "print(f'Average Precision: {avg_precision:.4f}')\n",
    "print(f'Average Recall: {avg_recall:.4f}')\n",
    "print(f'Average F1-score: {avg_f1_score:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee68ada6-4c3a-429a-89e8-c8586097ed57",
   "metadata": {},
   "source": [
    "## EffecientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5e4cbae-5a0e-4388-99ef-3fbc9b31cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Assuming 'dataset/' is your dataset directory with 'Cancerous' and 'Healthy' subdirectories\n",
    "dataset = datasets.ImageFolder('C:/Users/lenovo/Downloads/Biglycan breast cancer dataset/', transform=transform)\n",
    "\n",
    "# Splitting the dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Creating data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf73f661-b9ff-4eb9-92f0-9c748cf21cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): ConvNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): ConvNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=True)\n",
       "    (1): Linear(in_features=1280, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a pre-trained EfficientNet-B0 model\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# Freeze all the parameters in the model to prevent them from being updated during training\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the classifier layer for binary classification\n",
    "num_ftrs = model.classifier[1].in_features  # Get the input feature size of the original classifier\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(num_ftrs, 1)  # Binary classification\n",
    ")\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ace5806-c47d-49b1-96a5-cbdd00a24b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)  # Optimize only the classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17dd506d-933a-49ec-b0bf-9eb2cc52c2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6601023475329081\n",
      "Epoch 2, Loss: 0.5709017515182495\n",
      "Epoch 3, Loss: 0.5013017058372498\n",
      "Epoch 4, Loss: 0.4579740994506412\n",
      "Epoch 5, Loss: 0.4136607415146298\n",
      "Epoch 6, Loss: 0.39018183946609497\n",
      "Epoch 7, Loss: 0.36962048874961007\n",
      "Epoch 8, Loss: 0.3469744821389516\n",
      "Epoch 9, Loss: 0.352952735291587\n",
      "Epoch 10, Loss: 0.3300986952251858\n",
      "Epoch 11, Loss: 0.31039397915204364\n",
      "Epoch 12, Loss: 0.32183920509285396\n",
      "Epoch 13, Loss: 0.3050554063585069\n",
      "Epoch 14, Loss: 0.2975093358092838\n",
      "Epoch 15, Loss: 0.3112492693795098\n",
      "Epoch 16, Loss: 0.2828032755189472\n",
      "Epoch 17, Loss: 0.265971377491951\n",
      "Epoch 18, Loss: 0.2495581954717636\n",
      "Epoch 19, Loss: 0.24754688640435538\n",
      "Epoch 20, Loss: 0.25602660907639396\n",
      "Epoch 21, Loss: 0.22781111962265438\n",
      "Epoch 22, Loss: 0.24004303415616354\n",
      "Epoch 23, Loss: 0.22400512297948202\n",
      "Epoch 24, Loss: 0.2348979479736752\n",
      "Epoch 25, Loss: 0.2440014680226644\n",
      "Epoch 26, Loss: 0.23362939556439719\n",
      "Epoch 27, Loss: 0.22234112521012625\n",
      "Epoch 28, Loss: 0.22051024436950684\n",
      "Epoch 29, Loss: 0.22387318313121796\n",
      "Epoch 30, Loss: 0.19605729480584463\n",
      "Epoch 31, Loss: 0.20285368959108988\n",
      "Epoch 32, Loss: 0.19340314964453378\n",
      "Epoch 33, Loss: 0.18612682653797996\n",
      "Epoch 34, Loss: 0.22384336921903822\n",
      "Epoch 35, Loss: 0.19419817295339373\n",
      "Epoch 36, Loss: 0.22591979967223275\n",
      "Epoch 37, Loss: 0.18036933574411604\n",
      "Epoch 38, Loss: 0.1680578887462616\n",
      "Epoch 39, Loss: 0.20637518746985328\n",
      "Epoch 40, Loss: 0.15267771730820337\n",
      "Epoch 41, Loss: 0.20320367068052292\n",
      "Epoch 42, Loss: 0.1793897185060713\n",
      "Epoch 43, Loss: 0.2346938434574339\n",
      "Epoch 44, Loss: 0.18379301495022243\n",
      "Epoch 45, Loss: 0.2118660741382175\n",
      "Epoch 46, Loss: 0.1600910516248809\n",
      "Epoch 47, Loss: 0.1707166251209047\n",
      "Epoch 48, Loss: 0.16297569705380333\n",
      "Epoch 49, Loss: 0.20094413889778984\n",
      "Epoch 50, Loss: 0.15329583237568536\n",
      "Epoch 51, Loss: 0.18940754814280403\n",
      "Epoch 52, Loss: 0.18496229334010017\n",
      "Epoch 53, Loss: 0.20601593289110395\n",
      "Epoch 54, Loss: 0.1686430126428604\n",
      "Epoch 55, Loss: 0.15070830451117623\n",
      "Epoch 56, Loss: 0.17326224015818703\n",
      "Epoch 57, Loss: 0.17449792640076744\n",
      "Epoch 58, Loss: 0.17014623019430372\n",
      "Epoch 59, Loss: 0.155312932199902\n",
      "Epoch 60, Loss: 0.15339092827505535\n",
      "Epoch 61, Loss: 0.14006726857688692\n",
      "Epoch 62, Loss: 0.1421339205569691\n",
      "Epoch 63, Loss: 0.15318973693582746\n",
      "Epoch 64, Loss: 0.15009253554873997\n",
      "Epoch 65, Loss: 0.1930333317981826\n",
      "Epoch 66, Loss: 0.12661626521084043\n",
      "Epoch 67, Loss: 0.12981443189912373\n",
      "Epoch 68, Loss: 0.15635381804572213\n",
      "Epoch 69, Loss: 0.1386018859015571\n",
      "Epoch 70, Loss: 0.1616109369529618\n",
      "Epoch 71, Loss: 0.14249122391144434\n",
      "Epoch 72, Loss: 0.12830261844727728\n",
      "Epoch 73, Loss: 0.14103401949008307\n",
      "Epoch 74, Loss: 0.14635255601671007\n",
      "Epoch 75, Loss: 0.16136418862475288\n",
      "Epoch 76, Loss: 0.1433817661470837\n",
      "Epoch 77, Loss: 0.13345846119854185\n",
      "Epoch 78, Loss: 0.14679743432336384\n",
      "Epoch 79, Loss: 0.14554516557190153\n",
      "Epoch 80, Loss: 0.13815343462758595\n",
      "Epoch 81, Loss: 0.13713749084207746\n",
      "Epoch 82, Loss: 0.11416019333733453\n",
      "Epoch 83, Loss: 0.149928764336639\n",
      "Epoch 84, Loss: 0.10954661832915412\n",
      "Epoch 85, Loss: 0.1397316422727373\n",
      "Epoch 86, Loss: 0.1509962504108747\n",
      "Epoch 87, Loss: 0.13734614435169432\n",
      "Epoch 88, Loss: 0.14628068606058756\n",
      "Epoch 89, Loss: 0.13835422694683075\n",
      "Epoch 90, Loss: 0.1484604792462455\n",
      "Epoch 91, Loss: 0.11962906436787711\n",
      "Epoch 92, Loss: 0.12596246682935291\n",
      "Epoch 93, Loss: 0.11986770398086971\n",
      "Epoch 94, Loss: 0.10529122584395939\n",
      "Epoch 95, Loss: 0.14538254919979307\n",
      "Epoch 96, Loss: 0.1173263502617677\n",
      "Epoch 97, Loss: 0.13476194855239657\n",
      "Epoch 98, Loss: 0.1292462961541282\n",
      "Epoch 99, Loss: 0.13622310509284338\n",
      "Epoch 100, Loss: 0.12674138363864687\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100  # Adjust according to your needs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1).type_as(outputs))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70e6dc65-df62-4e0b-bb65-01ade5956104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.76%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Apply sigmoid since we used BCEWithLogitsLoss\n",
    "        predicted_probs = torch.sigmoid(outputs)\n",
    "        \n",
    "        # Convert probabilities to predicted class (0 or 1)\n",
    "        predicted = predicted_probs > 0.5\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.flatten() == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba4b543a-02ba-4dfd-9e98-a35023a61a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[34  5]\n",
      " [ 4 25]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.89      0.87      0.88        39\n",
      "   Cancerous       0.83      0.86      0.85        29\n",
      "\n",
      "    accuracy                           0.87        68\n",
      "   macro avg       0.86      0.87      0.87        68\n",
      "weighted avg       0.87      0.87      0.87        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_targets, np.array(all_preds).flatten()))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_targets, np.array(all_preds).flatten(), target_names=['Healthy', 'Cancerous']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44112b3-e1f5-472f-84f5-0b794ed6794a",
   "metadata": {},
   "source": [
    "## EfficientNet- 10 Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8449525-6160-4414-abd7-4a50b495dbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3584\n",
      "Epoch [20/50], Training Loss: 0.2559\n",
      "Epoch [30/50], Training Loss: 0.2750\n",
      "Epoch [40/50], Training Loss: 0.2221\n",
      "Epoch [50/50], Training Loss: 0.2171\n",
      "Validation Loss: 0.2391, Accuracy: 97.06%, Precision: 1.0000, Recall: 0.9333, F1-score: 0.9655\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3336\n",
      "Epoch [20/50], Training Loss: 0.2807\n",
      "Epoch [30/50], Training Loss: 0.2261\n",
      "Epoch [40/50], Training Loss: 0.2296\n",
      "Epoch [50/50], Training Loss: 0.1673\n",
      "Validation Loss: 0.2607, Accuracy: 85.29%, Precision: 0.9000, Recall: 0.6923, F1-score: 0.7826\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3473\n",
      "Epoch [20/50], Training Loss: 0.2883\n",
      "Epoch [30/50], Training Loss: 0.2485\n",
      "Epoch [40/50], Training Loss: 0.2096\n",
      "Epoch [50/50], Training Loss: 0.1849\n",
      "Validation Loss: 0.4383, Accuracy: 91.18%, Precision: 0.8571, Recall: 0.9231, F1-score: 0.8889\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3651\n",
      "Epoch [20/50], Training Loss: 0.2713\n",
      "Epoch [30/50], Training Loss: 0.2425\n",
      "Epoch [40/50], Training Loss: 0.2181\n",
      "Epoch [50/50], Training Loss: 0.2072\n",
      "Validation Loss: 0.2941, Accuracy: 88.24%, Precision: 0.7692, Recall: 0.9091, F1-score: 0.8333\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3551\n",
      "Epoch [20/50], Training Loss: 0.2752\n",
      "Epoch [30/50], Training Loss: 0.2541\n",
      "Epoch [40/50], Training Loss: 0.1985\n",
      "Epoch [50/50], Training Loss: 0.2113\n",
      "Validation Loss: 0.1464, Accuracy: 94.12%, Precision: 0.8750, Recall: 1.0000, F1-score: 0.9333\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3393\n",
      "Epoch [20/50], Training Loss: 0.2869\n",
      "Epoch [30/50], Training Loss: 0.2336\n",
      "Epoch [40/50], Training Loss: 0.1902\n",
      "Epoch [50/50], Training Loss: 0.2003\n",
      "Validation Loss: 0.2486, Accuracy: 85.29%, Precision: 0.8824, Recall: 0.8333, F1-score: 0.8571\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3674\n",
      "Epoch [20/50], Training Loss: 0.2809\n",
      "Epoch [30/50], Training Loss: 0.2640\n",
      "Epoch [40/50], Training Loss: 0.1901\n",
      "Epoch [50/50], Training Loss: 0.2200\n",
      "Validation Loss: 0.1346, Accuracy: 90.91%, Precision: 0.9167, Recall: 0.8462, F1-score: 0.8800\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3664\n",
      "Epoch [20/50], Training Loss: 0.2773\n",
      "Epoch [30/50], Training Loss: 0.2186\n",
      "Epoch [40/50], Training Loss: 0.2069\n",
      "Epoch [50/50], Training Loss: 0.2144\n",
      "Validation Loss: 0.1480, Accuracy: 90.91%, Precision: 0.8333, Recall: 0.9091, F1-score: 0.8696\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3148\n",
      "Epoch [20/50], Training Loss: 0.2538\n",
      "Epoch [30/50], Training Loss: 0.2341\n",
      "Epoch [40/50], Training Loss: 0.2102\n",
      "Epoch [50/50], Training Loss: 0.2123\n",
      "Validation Loss: 0.2737, Accuracy: 84.85%, Precision: 0.7692, Recall: 0.8333, F1-score: 0.8000\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.3747\n",
      "Epoch [20/50], Training Loss: 0.2837\n",
      "Epoch [30/50], Training Loss: 0.2350\n",
      "Epoch [40/50], Training Loss: 0.2431\n",
      "Epoch [50/50], Training Loss: 0.1702\n",
      "Validation Loss: 0.2111, Accuracy: 87.88%, Precision: 0.8000, Recall: 0.9231, F1-score: 0.8571\n",
      "\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "Average Loss: 0.2394\n",
      "Average Accuracy: 89.57%\n",
      "Average Precision: 0.8603\n",
      "Average Recall: 0.8803\n",
      "Average F1-score: 0.8668\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Define device upfront\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = 'C:/Users/lenovo/Downloads/Biglycan breast cancer dataset/'\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "def get_model(device):\n",
    "    # Load the pretrained EfficientNet_B0 model\n",
    "    model = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "    # Freeze all the parameters in the model to prevent them from being updated during training\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace the classifier layer for binary classification\n",
    "    # Note: Ensure you are accessing the correct layer for modification,\n",
    "    # EfficientNet_B0's classifier might have a different structure in future torchvision releases\n",
    "    num_ftrs = model.classifier[1].in_features  # Get the input feature size of the original classifier\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),  # Dropout layer for regularization\n",
    "        nn.Linear(num_ftrs, 1)  # Adjusted for binary classification\n",
    "    )\n",
    "\n",
    "    # Move the model to the specified device (GPU or CPU)\n",
    "    return model.to(device)\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, device, epochs=50):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)  # Adjust for BCEWithLogitsLoss\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))  # Adjust labels' shape\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        if (epoch+1) % 10 == 0:  # Print every 10 epochs\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Training Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "\n",
    "def evaluate_model(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            running_loss += loss.item()\n",
    "            preds = torch.sigmoid(outputs) > 0.5  # Convert to binary predictions\n",
    "            # Ensure preds and labels are at least 1D arrays before extending\n",
    "            all_predictions.extend(np.atleast_1d(preds.squeeze().cpu().numpy()))\n",
    "            all_labels.extend(np.atleast_1d(labels.cpu().numpy()))\n",
    "\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(all_labels, all_predictions, average='binary')\n",
    "\n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "    accuracy = (all_predictions == all_labels).mean() * 100\n",
    "    print(f'Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1_score:.4f}')\n",
    "    return avg_loss, accuracy, precision, recall, f1_score\n",
    "\n",
    "\n",
    "# Criterion adjusted for binary classification with a single output unit\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "k_folds = 10\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    train_subsampler = Subset(dataset, train_ids)\n",
    "    val_subsampler = Subset(dataset, val_ids)\n",
    "    \n",
    "    train_loader = DataLoader(train_subsampler, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_subsampler, batch_size=16)\n",
    "    \n",
    "    model = get_model(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Now specifying epochs=100 for training\n",
    "    train_model(model, train_loader, criterion, optimizer, device, epochs=50)\n",
    "    \n",
    "    avg_loss, accuracy, precision, recall, f1_score = evaluate_model(model, val_loader, criterion, device)\n",
    "\n",
    "    results.append((avg_loss, accuracy, precision, recall, f1_score))\n",
    "\n",
    "\n",
    "# After all folds are complete, calculate and print the average loss and accuracy across all folds\n",
    "# After evaluating all folds\n",
    "avg_loss = np.mean([result[0] for result in results])\n",
    "avg_accuracy = np.mean([result[1] for result in results])\n",
    "avg_precision = np.mean([result[2] for result in results])\n",
    "avg_recall = np.mean([result[3] for result in results])\n",
    "avg_f1_score = np.mean([result[4] for result in results])\n",
    "\n",
    "print(f'\\nK-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "print(f'Average Loss: {avg_loss:.4f}')\n",
    "print(f'Average Accuracy: {avg_accuracy:.2f}%')\n",
    "print(f'Average Precision: {avg_precision:.4f}')\n",
    "print(f'Average Recall: {avg_recall:.4f}')\n",
    "print(f'Average F1-score: {avg_f1_score:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade0c34f-be54-4760-bddd-86a353e4458d",
   "metadata": {},
   "source": [
    "## My algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "688f991e-b333-41e3-b727-2edf3990e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BinaryClassificationCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassificationCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(256 * 14 * 14, 512)  # Adjust the size according to your input image size\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = x.view(-1, 256 * 14 * 14)  # Flatten the output for the dense layer\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)  # No activation, nn.BCEWithLogitsLoss applies it internally\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b3dc792-efd5-4a51-8e26-19da7496e00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Assuming the BinaryClassificationCNN class definition is already provided\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to fit the model\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = datasets.ImageFolder('C:/Users/lenovo/Downloads/Biglycan breast cancer dataset/', transform=transform)\n",
    "\n",
    "# Splitting dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2c2fb93-62ec-42da-9180-14eee76604da",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = BinaryClassificationCNN().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9a70b0f-8e14-47a3-b4c4-0fb0de3a5321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 7.853662808736165\n",
      "Epoch 2/50, Loss: 1.427810827891032\n",
      "Epoch 3/50, Loss: 1.4601164327727423\n",
      "Epoch 4/50, Loss: 0.9993891484207578\n",
      "Epoch 5/50, Loss: 0.726152628660202\n",
      "Epoch 6/50, Loss: 0.5077841861380471\n",
      "Epoch 7/50, Loss: 0.4611706460515658\n",
      "Epoch 8/50, Loss: 0.3107933923602104\n",
      "Epoch 9/50, Loss: 0.22966955105463663\n",
      "Epoch 10/50, Loss: 0.41189462774329716\n",
      "Epoch 11/50, Loss: 0.27967242565419936\n",
      "Epoch 12/50, Loss: 0.4948378668891059\n",
      "Epoch 13/50, Loss: 0.25884318517314064\n",
      "Epoch 14/50, Loss: 0.34087637149625355\n",
      "Epoch 15/50, Loss: 0.22077318363719517\n",
      "Epoch 16/50, Loss: 0.7030209203561147\n",
      "Epoch 17/50, Loss: 0.25538038048479295\n",
      "Epoch 18/50, Loss: 0.3219006293349796\n",
      "Epoch 19/50, Loss: 0.3904445353481505\n",
      "Epoch 20/50, Loss: 0.3962450789080726\n",
      "Epoch 21/50, Loss: 0.18524051871564653\n",
      "Epoch 22/50, Loss: 0.1546869476636251\n",
      "Epoch 23/50, Loss: 0.13482591344250572\n",
      "Epoch 24/50, Loss: 0.11191048183374935\n",
      "Epoch 25/50, Loss: 0.1337103827132119\n",
      "Epoch 26/50, Loss: 0.14352568445934188\n",
      "Epoch 27/50, Loss: 0.6529762546221415\n",
      "Epoch 28/50, Loss: 0.22348616934484905\n",
      "Epoch 29/50, Loss: 0.4681795405017005\n",
      "Epoch 30/50, Loss: 0.33960340544581413\n",
      "Epoch 31/50, Loss: 0.1432387348678377\n",
      "Epoch 32/50, Loss: 0.2213392485347059\n",
      "Epoch 33/50, Loss: 0.19365423089928097\n",
      "Epoch 34/50, Loss: 0.15783936426871353\n",
      "Epoch 35/50, Loss: 0.0893644851942857\n",
      "Epoch 36/50, Loss: 0.08555928866068523\n",
      "Epoch 37/50, Loss: 0.06062897750073009\n",
      "Epoch 38/50, Loss: 0.06259862954417865\n",
      "Epoch 39/50, Loss: 0.06999752246257332\n",
      "Epoch 40/50, Loss: 0.07443646072513527\n",
      "Epoch 41/50, Loss: 0.1701014649329914\n",
      "Epoch 42/50, Loss: 0.0661408750133382\n",
      "Epoch 43/50, Loss: 0.06095033780568176\n",
      "Epoch 44/50, Loss: 0.09373233674301042\n",
      "Epoch 45/50, Loss: 0.15041950013902453\n",
      "Epoch 46/50, Loss: 0.08941149794393116\n",
      "Epoch 47/50, Loss: 0.16182288403312364\n",
      "Epoch 48/50, Loss: 0.12429989998539288\n",
      "Epoch 49/50, Loss: 0.06840296772619088\n",
      "Epoch 50/50, Loss: 0.08794584001104037\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float()  # Ensure labels are float\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs.squeeze(), labels)  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}')\n",
    "    \n",
    "    # Optional: Add validation loop here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a7a733b-4f1f-4e2b-b13d-939205bfc65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6674602627754211, Accuracy: 85.29411764705883%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "val_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        val_loss += loss.item()\n",
    "        \n",
    "        predicted = torch.sigmoid(outputs).squeeze() > 0.5  # Apply sigmoid and threshold\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f'Validation Loss: {val_loss/len(val_loader)}, Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1a11e4e-736f-4713-8494-d6b90463e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:  # Assuming val_loader is your DataLoader for the validation set\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Convert outputs to predicted class (0 or 1) using a threshold of 0.5\n",
    "        preds = torch.sigmoid(outputs).squeeze() > 0.5\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays for sklearn\n",
    "all_preds = np.array(all_preds, dtype=int)\n",
    "all_targets = np.array(all_targets, dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8721329e-2fef-4637-b87c-e7bf9aaac58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33  3]\n",
      " [ 7 25]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62c40de3-c875-4958-9407-790bb5953755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[33  3]\n",
      " [ 7 25]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.82      0.92      0.87        36\n",
      "   Cancerous       0.89      0.78      0.83        32\n",
      "\n",
      "    accuracy                           0.85        68\n",
      "   macro avg       0.86      0.85      0.85        68\n",
      "weighted avg       0.86      0.85      0.85        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_targets, np.array(all_preds).flatten()))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_targets, np.array(all_preds).flatten(), target_names=['Healthy', 'Cancerous']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "840f3254-31b3-4d68-9a61-5edcfcd50acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define the preprocessing pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
    "])\n",
    "\n",
    "# Load your image (replace 'path_to_your_image.jpg' with the actual file path)\n",
    "img_path = \"C:/Users/lenovo/Downloads/Biglycan breast cancer dataset/CANCER/12239 (12) (1).png\"\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "# Apply the preprocessing to the image\n",
    "input_tensor = transform(img)\n",
    "\n",
    "# Add a batch dimension (B, C, H, W), where B = 1\n",
    "input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "# Now, input_tensor is ready to be passed into your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88cc9556-6d60-4ea5-b274-3ce062b3e32a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Conv2d' object has no attribute 'gradients'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 67\u001b[0m\n\u001b[0;32m     65\u001b[0m input_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/lenovo/Downloads/Biglycan breast cancer dataset/CANCER/12239 (12) (1).png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     66\u001b[0m target_layer \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconv4  \u001b[38;5;66;03m# Assuming you want to use the last conv layer\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m \u001b[43mapply_gradcam\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_layer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 34\u001b[0m, in \u001b[0;36mapply_gradcam\u001b[1;34m(input_image_path, model, target_layer)\u001b[0m\n\u001b[0;32m     31\u001b[0m target\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Extract activations and gradients from the target layer\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m gradients \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradients\u001b[49m  \u001b[38;5;66;03m# Assuming you've implemented gradient capture\u001b[39;00m\n\u001b[0;32m     35\u001b[0m activations \u001b[38;5;241m=\u001b[39m target_layer\u001b[38;5;241m.\u001b[39mactivations  \u001b[38;5;66;03m# Assuming you've implemented activation capture\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Pool the gradients across the channels and weight the channels\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\anish1\\lib\\site-packages\\torch\\nn\\modules\\module.py:1177\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1176\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1177\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Conv2d' object has no attribute 'gradients'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# \n",
    "\n",
    "def apply_gradcam(input_image_path, model, target_layer):\n",
    "    # Preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    img = Image.open(input_image_path).convert(\"RGB\")\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Forward pass for the model to get logits\n",
    "    model.eval()\n",
    "    logits = model(img_tensor)\n",
    "\n",
    "    # Backward pass for gradient calculation\n",
    "    target = logits  # Assuming binary classification and single output neuron\n",
    "    model.zero_grad()\n",
    "    target.backward()\n",
    "\n",
    "    # Extract activations and gradients from the target layer\n",
    "    gradients = target_layer.gradients  # Assuming you've implemented gradient capture\n",
    "    activations = target_layer.activations  # Assuming you've implemented activation capture\n",
    "\n",
    "    # Pool the gradients across the channels and weight the channels\n",
    "    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "    for i in range(gradients.shape[1]):  # Number of channels\n",
    "        activations[:, i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "    # Generate the heatmap\n",
    "    heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "    heatmap = np.maximum(heatmap.detach().cpu().numpy(), 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "\n",
    "    # Resize the heatmap to the original image size\n",
    "    heatmap = cv2.resize(heatmap, (img.width, img.height))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = heatmap * 0.4 + np.array(img)\n",
    "    superimposed_img = np.clip(superimposed_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Initialize your model\n",
    "model = BinaryClassificationCNN()\n",
    "\n",
    "# Example usage\n",
    "input_image_path = 'C:/Users/lenovo/Downloads/Biglycan breast cancer dataset/CANCER/12239 (12) (1).png'\n",
    "target_layer = model.conv4  # Assuming you want to use the last conv layer\n",
    "apply_gradcam(input_image_path, model, target_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55046680-55dc-4568-9e07-1c61c8b1f231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c8119d3-b005-43c4-ae9a-10c088f19f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d476ed4-e0c0-4f62-ac27-bc45ae542358",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4be6d2d-35aa-452a-b8ec-a7e72a683b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Setup dataset (adjust path as necessary)\n",
    "data_folder = 'C:/Users/lenovo/Downloads/Biglycan breast cancer dataset/'\n",
    "full_dataset = datasets.ImageFolder(root=data_folder, transform=transform)\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f841aef3-43a9-458b-aca4-6e8b7f2c8eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with LR: 0.01, Batch Size: 16\n",
      "Validation Accuracy: 0.7941176470588235\n",
      "Training with LR: 0.01, Batch Size: 32\n",
      "Validation Accuracy: 0.7941176470588235\n",
      "Training with LR: 0.01, Batch Size: 64\n",
      "Validation Accuracy: 0.8088235294117647\n",
      "Training with LR: 0.001, Batch Size: 16\n",
      "Validation Accuracy: 0.7647058823529411\n",
      "Training with LR: 0.001, Batch Size: 32\n",
      "Validation Accuracy: 0.7058823529411765\n",
      "Training with LR: 0.001, Batch Size: 64\n",
      "Validation Accuracy: 0.7941176470588235\n",
      "Training with LR: 0.0001, Batch Size: 16\n",
      "Validation Accuracy: 0.8382352941176471\n",
      "Training with LR: 0.0001, Batch Size: 32\n",
      "Validation Accuracy: 0.8088235294117647\n",
      "Training with LR: 0.0001, Batch Size: 64\n",
      "Validation Accuracy: 0.7794117647058824\n",
      "Best Accuracy: 0.8382352941176471\n",
      "Best Parameters: {'lr': 0.0001, 'batch_size': 16}\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [16, 32, 64]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"Training with LR: {lr}, Batch Size: {batch_size}\")\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "        model = BinaryClassificationCNN().to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        # Simplified training loop\n",
    "        for epoch in range(10):  # Let's limit to 3 epochs for brevity\n",
    "            model.train()\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Simplified validation loop\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "                outputs = model(inputs)\n",
    "                predicted = torch.sigmoid(outputs).squeeze() > 0.5\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels.squeeze()).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        print(f\"Validation Accuracy: {accuracy}\")\n",
    "\n",
    "        # Track the best parameters\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = {'lr': lr, 'batch_size': batch_size}\n",
    "\n",
    "print(f\"Best Accuracy: {best_accuracy}\")\n",
    "print(f\"Best Parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfb2ae0-fa9e-4454-ab18-8de90b8e8595",
   "metadata": {},
   "source": [
    "## Proposed Algorithm - 10 Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f598718-3e36-46df-9697-4e8a2d1faa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.1936\n",
      "Epoch [20/50], Training Loss: 0.0470\n",
      "Epoch [30/50], Training Loss: 0.0132\n",
      "Epoch [40/50], Training Loss: 0.0055\n",
      "Epoch [50/50], Training Loss: 0.0042\n",
      "Validation Loss: 0.2437, Accuracy: 94.12%, Precision: 0.9000, Recall: 0.9000, F1-score: 0.9000\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.1656\n",
      "Epoch [20/50], Training Loss: 0.0478\n",
      "Epoch [30/50], Training Loss: 0.0176\n",
      "Epoch [40/50], Training Loss: 0.0173\n",
      "Epoch [50/50], Training Loss: 0.0384\n",
      "Validation Loss: 0.1486, Accuracy: 88.24%, Precision: 0.7857, Recall: 0.9167, F1-score: 0.8462\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.2644\n",
      "Epoch [20/50], Training Loss: 0.1917\n",
      "Epoch [30/50], Training Loss: 0.0558\n",
      "Epoch [40/50], Training Loss: 0.0198\n",
      "Epoch [50/50], Training Loss: 0.0042\n",
      "Validation Loss: 0.2674, Accuracy: 88.24%, Precision: 0.8333, Recall: 0.9375, F1-score: 0.8824\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.1669\n",
      "Epoch [20/50], Training Loss: 0.0422\n",
      "Epoch [30/50], Training Loss: 0.0123\n",
      "Epoch [40/50], Training Loss: 0.0109\n",
      "Epoch [50/50], Training Loss: 0.0384\n",
      "Validation Loss: 0.1830, Accuracy: 91.18%, Precision: 0.8667, Recall: 0.9286, F1-score: 0.8966\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.1671\n",
      "Epoch [20/50], Training Loss: 0.0831\n",
      "Epoch [30/50], Training Loss: 0.0159\n",
      "Epoch [40/50], Training Loss: 0.0082\n",
      "Epoch [50/50], Training Loss: 0.0052\n",
      "Validation Loss: 0.2073, Accuracy: 94.12%, Precision: 0.9286, Recall: 0.9286, F1-score: 0.9286\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.2171\n",
      "Epoch [20/50], Training Loss: 0.1281\n",
      "Epoch [30/50], Training Loss: 0.0296\n",
      "Epoch [40/50], Training Loss: 0.0200\n",
      "Epoch [50/50], Training Loss: 0.0089\n",
      "Validation Loss: 0.2322, Accuracy: 88.24%, Precision: 0.9286, Recall: 0.8125, F1-score: 0.8667\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.1716\n",
      "Epoch [20/50], Training Loss: 0.0546\n",
      "Epoch [30/50], Training Loss: 0.0579\n",
      "Epoch [40/50], Training Loss: 0.0509\n",
      "Epoch [50/50], Training Loss: 0.0113\n",
      "Validation Loss: 0.1604, Accuracy: 93.94%, Precision: 0.8667, Recall: 1.0000, F1-score: 0.9286\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.1638\n",
      "Epoch [20/50], Training Loss: 0.0421\n",
      "Epoch [30/50], Training Loss: 0.0321\n",
      "Epoch [40/50], Training Loss: 0.0233\n",
      "Epoch [50/50], Training Loss: 0.0619\n",
      "Validation Loss: 0.0482, Accuracy: 96.97%, Precision: 1.0000, Recall: 0.9231, F1-score: 0.9600\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.1069\n",
      "Epoch [20/50], Training Loss: 0.0866\n",
      "Epoch [30/50], Training Loss: 0.0091\n",
      "Epoch [40/50], Training Loss: 0.0056\n",
      "Epoch [50/50], Training Loss: 0.0011\n",
      "Validation Loss: 0.5067, Accuracy: 87.88%, Precision: 0.8000, Recall: 0.8000, F1-score: 0.8000\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.1888\n",
      "Epoch [20/50], Training Loss: 0.0601\n",
      "Epoch [30/50], Training Loss: 0.0341\n",
      "Epoch [40/50], Training Loss: 0.0275\n",
      "Epoch [50/50], Training Loss: 0.0023\n",
      "Validation Loss: 0.0944, Accuracy: 93.94%, Precision: 0.9333, Recall: 0.9333, F1-score: 0.9333\n",
      "\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "Average Loss: 0.2092\n",
      "Average Accuracy: 91.68%\n",
      "Average Precision: 0.8843\n",
      "Average Recall: 0.9080\n",
      "Average F1-score: 0.8942\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "# Define device upfront\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = 'C:/Users/lenovo/Downloads/Biglycan breast cancer dataset/'\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "def get_model(device):\n",
    "    # Assuming BinaryClassificationCNN is a previously defined model for binary classification\n",
    "    model = BinaryClassificationCNN()  # Use your model here\n",
    "    return model.to(device)\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, device, epochs=50):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)  # Adjust for BCEWithLogitsLoss\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))  # Adjust labels' shape\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        if (epoch+1) % 10 == 0:  # Print every 10 epochs\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Training Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "def evaluate_model(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            running_loss += loss.item()\n",
    "            preds = torch.sigmoid(outputs) > 0.5  # Convert to binary predictions\n",
    "            # Ensure preds and labels are at least 1D arrays before extending\n",
    "            all_predictions.extend(np.atleast_1d(preds.squeeze().cpu().numpy()))\n",
    "            all_labels.extend(np.atleast_1d(labels.cpu().numpy()))\n",
    "\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(all_labels, all_predictions, average='binary')\n",
    "\n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "    accuracy = (all_predictions == all_labels).mean() * 100\n",
    "    print(f'Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1_score:.4f}')\n",
    "    return avg_loss, accuracy, precision, recall, f1_score\n",
    "\n",
    "\n",
    "# Criterion adjusted for binary classification with a single output unit\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "k_folds = 10  # Change from 5 to 10 for 10-fold cross-validation\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    train_subsampler = Subset(dataset, train_ids)\n",
    "    val_subsampler = Subset(dataset, val_ids)\n",
    "    \n",
    "    train_loader = DataLoader(train_subsampler, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_subsampler, batch_size=16)\n",
    "    \n",
    "    model = get_model(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    train_model(model, train_loader, criterion, optimizer, device, epochs=50)\n",
    "    \n",
    "    avg_loss, accuracy, precision, recall, f1_score = evaluate_model(model, val_loader, criterion, device)\n",
    "\n",
    "    results.append((avg_loss, accuracy, precision, recall, f1_score))\n",
    "\n",
    "avg_loss = np.mean([result[0] for result in results])\n",
    "avg_accuracy = np.mean([result[1] for result in results])\n",
    "avg_precision = np.mean([result[2] for result in results])\n",
    "avg_recall = np.mean([result[3] for result in results])\n",
    "avg_f1_score = np.mean([result[4] for result in results])\n",
    "\n",
    "print(f'\\nK-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "print(f'Average Loss: {avg_loss:.4f}')\n",
    "print(f'Average Accuracy: {avg_accuracy:.2f}%')\n",
    "print(f'Average Precision: {avg_precision:.4f}')\n",
    "print(f'Average Recall: {avg_recall:.4f}')\n",
    "print(f'Average F1-score: {avg_f1_score:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79f1d945-ee8f-4c7b-8313-749eb2aa6eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Assuming the BinaryClassificationCNN class definition is already provided\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to fit the model\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = datasets.ImageFolder('C:/Users/lenovo/Downloads/Biglycan breast cancer dataset/', transform=transform)\n",
    "\n",
    "# Splitting dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "752b695a-c224-405b-94af-e4e8f31b1e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = BinaryClassificationCNN().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b763e59-f8d2-4824-b62f-aeeb809db30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.0769436306813185\n",
      "Epoch 2/50, Loss: 0.6144414947313421\n",
      "Epoch 3/50, Loss: 0.40919125868993644\n",
      "Epoch 4/50, Loss: 0.3396902281571837\n",
      "Epoch 5/50, Loss: 0.22093496427816503\n",
      "Epoch 6/50, Loss: 0.4640796416822602\n",
      "Epoch 7/50, Loss: 0.3449540493242881\n",
      "Epoch 8/50, Loss: 0.3492835788604091\n",
      "Epoch 9/50, Loss: 0.2295837213887888\n",
      "Epoch 10/50, Loss: 0.18509838401394732\n",
      "Epoch 11/50, Loss: 0.11074921138146344\n",
      "Epoch 12/50, Loss: 0.07471664753906868\n",
      "Epoch 13/50, Loss: 0.15359422860338406\n",
      "Epoch 14/50, Loss: 0.1080382815836107\n",
      "Epoch 15/50, Loss: 0.1252198898616959\n",
      "Epoch 16/50, Loss: 0.07184543551000602\n",
      "Epoch 17/50, Loss: 0.06040382077095702\n",
      "Epoch 18/50, Loss: 0.04487014518064611\n",
      "Epoch 19/50, Loss: 0.0573450575774426\n",
      "Epoch 20/50, Loss: 0.031196470125852263\n",
      "Epoch 21/50, Loss: 0.03690545968985295\n",
      "Epoch 22/50, Loss: 0.022597969879451042\n",
      "Epoch 23/50, Loss: 0.015890615786809253\n",
      "Epoch 24/50, Loss: 0.02467205191907637\n",
      "Epoch 25/50, Loss: 0.018207409268464234\n",
      "Epoch 26/50, Loss: 0.01874736654024352\n",
      "Epoch 27/50, Loss: 0.042536661535611045\n",
      "Epoch 28/50, Loss: 0.05194154052365133\n",
      "Epoch 29/50, Loss: 0.1425045869203613\n",
      "Epoch 30/50, Loss: 0.07612872764687328\n",
      "Epoch 31/50, Loss: 0.10834628212101319\n",
      "Epoch 32/50, Loss: 0.11479468096513301\n",
      "Epoch 33/50, Loss: 0.055473320158746314\n",
      "Epoch 34/50, Loss: 0.05109263474450392\n",
      "Epoch 35/50, Loss: 0.022494154763134086\n",
      "Epoch 36/50, Loss: 0.09065312075921718\n",
      "Epoch 37/50, Loss: 0.04093740791465868\n",
      "Epoch 38/50, Loss: 0.02122836924322388\n",
      "Epoch 39/50, Loss: 0.055767666413243315\n",
      "Epoch 40/50, Loss: 0.03575820609009551\n",
      "Epoch 41/50, Loss: 0.023493141661781597\n",
      "Epoch 42/50, Loss: 0.006298326611559948\n",
      "Epoch 43/50, Loss: 0.02440505230333656\n",
      "Epoch 44/50, Loss: 0.029677665337016258\n",
      "Epoch 45/50, Loss: 0.03130363016594749\n",
      "Epoch 46/50, Loss: 0.023446494141620967\n",
      "Epoch 47/50, Loss: 0.005963911240756074\n",
      "Epoch 48/50, Loss: 0.005801329529597698\n",
      "Epoch 49/50, Loss: 0.01656353646574323\n",
      "Epoch 50/50, Loss: 0.0045840116123572975\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float()  # Ensure labels are float\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs.squeeze(), labels)  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}')\n",
    "    \n",
    "    # Optional: Add validation loop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "746c1049-a7a1-4f41-af36-37ec75b466d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.49687231332063675, Accuracy: 83.82352941176471%\n"
     ]
    }
   ],
   "source": [
    " model.eval()  # Set the model to evaluation mode\n",
    "val_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        val_loss += loss.item()\n",
    "        \n",
    "        predicted = torch.sigmoid(outputs).squeeze() > 0.5  # Apply sigmoid and threshold\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f'Validation Loss: {val_loss/len(val_loader)}, Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87e18e5b-ed9a-4e07-80dd-5d99a5fc3356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[44  6]\n",
      " [ 5 13]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.90      0.88      0.89        50\n",
      "   Cancerous       0.68      0.72      0.70        18\n",
      "\n",
      "    accuracy                           0.84        68\n",
      "   macro avg       0.79      0.80      0.80        68\n",
      "weighted avg       0.84      0.84      0.84        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_targets, np.array(all_preds).flatten()))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_targets, np.array(all_preds).flatten(), target_names=['Healthy', 'Cancerous']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0848b471-00f0-4931-9582-ebf6ac6f3b06",
   "metadata": {},
   "source": [
    "## MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54940bf7-d132-4399-8a94-e7db54313981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes=2):\n",
    "    # Load a pre-trained MobileNetV2 model\n",
    "    model = models.mobilenet_v2(pretrained=True)\n",
    "    \n",
    "    # Modify the classifier to fit the number of classes\n",
    "    model.classifier[1] = nn.Linear(model.last_channel, num_classes)\n",
    "    \n",
    "    # If binary classification, change the output layer to a single unit with sigmoid activation\n",
    "    if num_classes == 2:\n",
    "        model.classifier[1] = nn.Linear(model.last_channel, 1)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(num_classes=1)  # For binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "559761d0-7091-4290-ac19-58df84fa0262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Assuming the BinaryClassificationCNN class definition is already provided\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to fit the model\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = datasets.ImageFolder('C:/Users/lenovo/Downloads/Biglycan breast cancer dataset/', transform=transform)\n",
    "\n",
    "# Splitting dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c37d6666-afe7-4ba2-bc73-4be2b6014d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = create_model().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a588e5e-3418-4f06-bf43-b84d0b655421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.5349482788759119\n",
      "Epoch 2/50, Loss: 0.22295346943771138\n",
      "Epoch 3/50, Loss: 0.09588757946210749\n",
      "Epoch 4/50, Loss: 0.062006058500093574\n",
      "Epoch 5/50, Loss: 0.03620221071383532\n",
      "Epoch 6/50, Loss: 0.02118881290559383\n",
      "Epoch 7/50, Loss: 0.019684750805882847\n",
      "Epoch 8/50, Loss: 0.0235219247337869\n",
      "Epoch 9/50, Loss: 0.025950317764106917\n",
      "Epoch 10/50, Loss: 0.014860485159956357\n",
      "Epoch 11/50, Loss: 0.030102890594314563\n",
      "Epoch 12/50, Loss: 0.0595970931052066\n",
      "Epoch 13/50, Loss: 0.06659441713846344\n",
      "Epoch 14/50, Loss: 0.05088220488773111\n",
      "Epoch 15/50, Loss: 0.04401427942930775\n",
      "Epoch 16/50, Loss: 0.03336102479164872\n",
      "Epoch 17/50, Loss: 0.013831479221527629\n",
      "Epoch 18/50, Loss: 0.010874828025835621\n",
      "Epoch 19/50, Loss: 0.009696896910420893\n",
      "Epoch 20/50, Loss: 0.03736421662752571\n",
      "Epoch 21/50, Loss: 0.01739040335215738\n",
      "Epoch 22/50, Loss: 0.03978815864470294\n",
      "Epoch 23/50, Loss: 0.014711701235843493\n",
      "Epoch 24/50, Loss: 0.013089327535400277\n",
      "Epoch 25/50, Loss: 0.013992316712734891\n",
      "Epoch 26/50, Loss: 0.0986960751881056\n",
      "Epoch 27/50, Loss: 0.025497624773860854\n",
      "Epoch 28/50, Loss: 0.023604920781080556\n",
      "Epoch 29/50, Loss: 0.024884108662851814\n",
      "Epoch 30/50, Loss: 0.012772458153502905\n",
      "Epoch 31/50, Loss: 0.00892453531816821\n",
      "Epoch 32/50, Loss: 0.005728249354219502\n",
      "Epoch 33/50, Loss: 0.010289325163124459\n",
      "Epoch 34/50, Loss: 0.008162780373822898\n",
      "Epoch 35/50, Loss: 0.004730962983825628\n",
      "Epoch 36/50, Loss: 0.011364093887523803\n",
      "Epoch 37/50, Loss: 0.002295427121947903\n",
      "Epoch 38/50, Loss: 0.0032838114172644805\n",
      "Epoch 39/50, Loss: 0.0016383643198744668\n",
      "Epoch 40/50, Loss: 0.003957794241774964\n",
      "Epoch 41/50, Loss: 0.0014138731862390961\n",
      "Epoch 42/50, Loss: 0.0013591639649616007\n",
      "Epoch 43/50, Loss: 0.002674990938805208\n",
      "Epoch 44/50, Loss: 0.0005657708097714931\n",
      "Epoch 45/50, Loss: 0.021601664165192394\n",
      "Epoch 46/50, Loss: 0.01741291460177094\n",
      "Epoch 47/50, Loss: 0.015237226592623354\n",
      "Epoch 48/50, Loss: 0.006441115090103053\n",
      "Epoch 49/50, Loss: 0.002115998403443133\n",
      "Epoch 50/50, Loss: 0.0006792721696376033\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float()  # Ensure labels are float\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs.squeeze(), labels)  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9bcb6cd6-02a9-44a1-bd35-73d1d599bcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2368245217949152, Accuracy: 91.17647058823529%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "val_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        val_loss += loss.item()\n",
    "        \n",
    "        predicted = torch.sigmoid(outputs).squeeze() > 0.5  # Apply sigmoid and threshold\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f'Validation Loss: {val_loss/len(val_loader)}, Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c326eca-807c-4cfa-a177-af92f3789b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[36  1]\n",
      " [ 5 26]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.88      0.97      0.92        37\n",
      "   Cancerous       0.96      0.84      0.90        31\n",
      "\n",
      "    accuracy                           0.91        68\n",
      "   macro avg       0.92      0.91      0.91        68\n",
      "weighted avg       0.92      0.91      0.91        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_targets, np.array(all_preds).flatten()))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_targets, np.array(all_preds).flatten(), target_names=['Healthy', 'Cancerous']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc4094-1fb4-4b0c-9f0c-b613eb824c78",
   "metadata": {},
   "source": [
    "## MobileNet-10 Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb984b5c-9814-4360-9522-720200ed96da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.0414\n",
      "Epoch [20/50], Training Loss: 0.0501\n",
      "Epoch [30/50], Training Loss: 0.0614\n",
      "Epoch [40/50], Training Loss: 0.0176\n",
      "Epoch [50/50], Training Loss: 0.0230\n",
      "Validation Loss: 0.5249, Accuracy: 79.41%, Precision: 0.6875, Recall: 0.8462, F1-score: 0.7586\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.1072\n",
      "Epoch [20/50], Training Loss: 0.0604\n",
      "Epoch [30/50], Training Loss: 0.0041\n",
      "Epoch [40/50], Training Loss: 0.0780\n",
      "Epoch [50/50], Training Loss: 0.0566\n",
      "Validation Loss: 0.2398, Accuracy: 91.18%, Precision: 0.7857, Recall: 1.0000, F1-score: 0.8800\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.1335\n",
      "Epoch [20/50], Training Loss: 0.0646\n",
      "Epoch [30/50], Training Loss: 0.0060\n",
      "Epoch [40/50], Training Loss: 0.0938\n",
      "Epoch [50/50], Training Loss: 0.0094\n",
      "Validation Loss: 0.3891, Accuracy: 82.35%, Precision: 0.7692, Recall: 0.7692, F1-score: 0.7692\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.1314\n",
      "Epoch [20/50], Training Loss: 0.0518\n",
      "Epoch [30/50], Training Loss: 0.0407\n",
      "Epoch [40/50], Training Loss: 0.0833\n",
      "Epoch [50/50], Training Loss: 0.2723\n",
      "Validation Loss: 1.2463, Accuracy: 85.29%, Precision: 0.6923, Recall: 0.9000, F1-score: 0.7826\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.0917\n",
      "Epoch [20/50], Training Loss: 0.0587\n",
      "Epoch [30/50], Training Loss: 0.0275\n",
      "Epoch [40/50], Training Loss: 0.0035\n",
      "Epoch [50/50], Training Loss: 0.0863\n",
      "Validation Loss: 0.2281, Accuracy: 85.29%, Precision: 0.7778, Recall: 0.9333, F1-score: 0.8485\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.1768\n",
      "Epoch [20/50], Training Loss: 0.1407\n",
      "Epoch [30/50], Training Loss: 0.0209\n",
      "Epoch [40/50], Training Loss: 0.0384\n",
      "Epoch [50/50], Training Loss: 0.0046\n",
      "Validation Loss: 0.1850, Accuracy: 94.12%, Precision: 0.9474, Recall: 0.9474, F1-score: 0.9474\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.0678\n",
      "Epoch [20/50], Training Loss: 0.2032\n",
      "Epoch [30/50], Training Loss: 0.0159\n",
      "Epoch [40/50], Training Loss: 0.0242\n",
      "Epoch [50/50], Training Loss: 0.0579\n",
      "Validation Loss: 0.0461, Accuracy: 96.97%, Precision: 1.0000, Recall: 0.9167, F1-score: 0.9565\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.1099\n",
      "Epoch [20/50], Training Loss: 0.2561\n",
      "Epoch [30/50], Training Loss: 0.0326\n",
      "Epoch [40/50], Training Loss: 0.0496\n",
      "Epoch [50/50], Training Loss: 0.0320\n",
      "Validation Loss: 0.2402, Accuracy: 84.85%, Precision: 0.8667, Recall: 0.8125, F1-score: 0.8387\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.1047\n",
      "Epoch [20/50], Training Loss: 0.0704\n",
      "Epoch [30/50], Training Loss: 0.0207\n",
      "Epoch [40/50], Training Loss: 0.0664\n",
      "Epoch [50/50], Training Loss: 0.0029\n",
      "Validation Loss: 0.0781, Accuracy: 93.94%, Precision: 0.8462, Recall: 1.0000, F1-score: 0.9167\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Epoch [10/50], Training Loss: 0.0790\n",
      "Epoch [20/50], Training Loss: 0.0098\n",
      "Epoch [30/50], Training Loss: 0.0432\n",
      "Epoch [40/50], Training Loss: 0.0056\n",
      "Epoch [50/50], Training Loss: 0.0332\n",
      "Validation Loss: 0.3203, Accuracy: 90.91%, Precision: 0.8571, Recall: 0.9231, F1-score: 0.8889\n",
      "\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "Average Loss: 0.3498\n",
      "Average Accuracy: 88.43%\n",
      "Average Precision: 0.8230\n",
      "Average Recall: 0.9048\n",
      "Average F1-score: 0.8587\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Define device upfront\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = 'C:/Users/lenovo/Downloads/Biglycan breast cancer dataset/'\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "def get_model(device):\n",
    "    model = create_model()  # Use your model here\n",
    "    return model.to(device)\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, device, epochs=50):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)  # Adjust for BCEWithLogitsLoss\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))  # Adjust labels' shape\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        if (epoch+1) % 10 == 0:  # Print every 10 epochs\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Training Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "\n",
    "def evaluate_model(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            running_loss += loss.item()\n",
    "            preds = torch.sigmoid(outputs) > 0.5  # Convert to binary predictions\n",
    "            # Ensure preds and labels are at least 1D arrays before extending\n",
    "            all_predictions.extend(np.atleast_1d(preds.squeeze().cpu().numpy()))\n",
    "            all_labels.extend(np.atleast_1d(labels.cpu().numpy()))\n",
    "\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(all_labels, all_predictions, average='binary')\n",
    "\n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "    accuracy = (all_predictions == all_labels).mean() * 100\n",
    "    print(f'Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1_score:.4f}')\n",
    "    return avg_loss, accuracy, precision, recall, f1_score\n",
    "\n",
    "\n",
    "# Criterion adjusted for binary classification with a single output unit\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "k_folds = 10\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    train_subsampler = Subset(dataset, train_ids)\n",
    "    val_subsampler = Subset(dataset, val_ids)\n",
    "    \n",
    "    train_loader = DataLoader(train_subsampler, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_subsampler, batch_size=16)\n",
    "    \n",
    "    model = get_model(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Now specifying epochs=100 for training\n",
    "    train_model(model, train_loader, criterion, optimizer, device, epochs=50)\n",
    "    \n",
    "    avg_loss, accuracy, precision, recall, f1_score = evaluate_model(model, val_loader, criterion, device)\n",
    "\n",
    "    results.append((avg_loss, accuracy, precision, recall, f1_score))\n",
    "\n",
    "\n",
    "# After all folds are complete, calculate and print the average loss and accuracy across all folds\n",
    "# After evaluating all folds\n",
    "avg_loss = np.mean([result[0] for result in results])\n",
    "avg_accuracy = np.mean([result[1] for result in results])\n",
    "avg_precision = np.mean([result[2] for result in results])\n",
    "avg_recall = np.mean([result[3] for result in results])\n",
    "avg_f1_score = np.mean([result[4] for result in results])\n",
    "\n",
    "print(f'\\nK-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "print(f'Average Loss: {avg_loss:.4f}')\n",
    "print(f'Average Accuracy: {avg_accuracy:.2f}%')\n",
    "print(f'Average Precision: {avg_precision:.4f}')\n",
    "print(f'Average Recall: {avg_recall:.4f}')\n",
    "print(f'Average F1-score: {avg_f1_score:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e635305f-f937-4d52-999e-74fa4d436048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
